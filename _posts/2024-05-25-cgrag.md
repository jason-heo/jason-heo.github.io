---
layout: post
title: "CGRAG - How to generate accurate LLM responses on large code repositories"
categories: "llm"
---

요즘은 [reddit LocalLlama](https://www.reddit.com/r/LocalLLaMA/)에서 LLM에 대한 최신 정보를 얻고 있다.

그러던 중 https://www.reddit.com/r/LocalLLaMA/comments/1d0nd7p 에서 CGRAG라는 걸 알게 되었고, [medium 글](https://medium.com/@djangoist/e77c0ffe432d)에 좀 더 자세한 설명이 있었다.

읽어본 내용을 간단히 기록해 본다.

- Code Qwen 1.5는 context length가 64k이다
- 수천 line 정도의 소스 코드는 code 전체를 prompt에 넣어서 질의할 수 있다
- 그런데 code 크기가 큰 경우 64k로는 부족하다
- 이를 위해 CGRAG (Contextually-Guided)를 만들게 되었다
- CGRAG는 두 단계로 작동한다
  - 1st time: 사용자 질문을 해결하기 위해 필요한 concept을 LLM에게 질의한다
  - 2nd time: 해당 concept을 RAG로 찾은 후 LLM에게 전송

사용 사례

CGRAG를 구현 후 Django 프로젝트의 bug 티켓 본문 내용만 입력을 해서 bug가 발생한 code line을 거의 근접하게 찾았다고 한다.

CGRAG는 [dir-assistant](https://github.com/curvedinf/dir-assistant)에 추가된 기능이라고 하는데 솔직히 아직 정확한 작동 방법은 모르겠다.

reddit 댓글을 읽다가 알게 된 건데 https://github.com/fynnfluegge/codeqai 이런 프로젝트도 있었다. dir-assistant보다는 요게 좀 더 재미있을 듯 해서 조만간 요걸 공부해봐야겠다.
